---
title: 大预言模型和宏基因组应用
author: Huahui Ren
date: '2024-05-29'
slug: ''
categories:
  - 技术
tags:
  - microbiome
subtitle: ''
summary: ''
authors: []
lastmod: '2024-05-29T11:27:43+08:00'
featured: no
draft: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

最近在学习大语言模型的基础和在宏基因组中的应用，在这里总结下自己学习的内容和资料。

## **大语言模型基础**

1. 理解Transformer
   
    1.1  Transformer是大语言的基础，基于这篇[**博客**](https://prvnsmpth.github.io/animated-transformer/)首先学习下Transformer是什么。
    1.2  Token: 在Transformer模型中，“tokens”是指模型输入的基本单位，通常是文本中的单词、子词或字符。在Transformer的上下文中，文本会被分割成一系列token，并且每个token都会被转换成一个向量表示。在处理序列数据时，tokens是构成输入序列的基本单位，它们在模型中被依次处理，用于捕捉序列中的语言结构和语义信息。
    1.3 Embeddings: 
    1.4 

2. 

3. 


## **宏基因组应用相关文献**

1. 

2. 

3.